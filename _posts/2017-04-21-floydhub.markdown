---
layout: post
title:  "Deep Learning with Floydhub"
date:   2017-04-21 15:17:33 -0700
categories: deep learning
---
# Intro

We want to automatically generate original text based on Nietzsche's corpus. We will use a LSTM using Keras to model a character generator.

# Setup

- While looking for options to test deep learning training with GPU I came accross [FloydHub](http://www.floydhub.com), the Heroku for deep learning. It is easier to setup than AWS gpu instances.
- Install and get started [here](http://docs.floydhub.com/home/getting_started/)

``` sh
mkdir PROJECT_DIR
cd PROJECT_DIR
floyd login
floyd init PROJECT_NAME

mkdir DATA_DIR
cd DATA_DIR
wget https://s3.amazonaws.com/text-datasets/nietzsche.txt
floyd data init DATASET_NAME

floyd status
floyd data status
```

# Run jupyter notebook on GPU

``` bash
floyd run --data ID --mode jupyter
```
Which will give an URL to access the jupyter notebook

# Modeling
- We will use keras library for deep learning
- install keras and numpy if not already done

## module imports

``` python
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from keras.utils.data_utils import get_file
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.callbacks import ModelCheckpoint
import sys
from keras import backend as K
print K.backend()
%matplotlib inline
```

## Data 

``` python
    data_path = "/INPUT/nietzsche.txt"
    text = open(path).read()
    print('Corpus length:', len(text))
    chars = sorted(list(set(text)))
    vocab_size = len(chars)
    print('Total unique chars:', vocab_size)
    indices_from_chars = dict((c,i) for i, c in enumerate(chars))
```
